{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Natural language toolkit. Download if not installed already\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# For splitting by punctuation and using regex\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Evaluation and feature selection tools\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_funny</th>\n",
       "      <th>vote_cool</th>\n",
       "      <th>vote_useful</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dear longman &amp; eagle.......you've left me no c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Delish. The hubby and I wanted to do brunch on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yep, I've giving Yolk 5 stars. It's just reall...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Meat, meat, meat. It's meat-tastic. So much me...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I caught up with the law school girls on a Sat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_funny  vote_cool  vote_useful  \\\n",
       "0           0          1            3   \n",
       "1           0          0            0   \n",
       "2           1          0            1   \n",
       "3          17          3            3   \n",
       "4           0          0            0   \n",
       "\n",
       "                                              review  rating  \n",
       "0  dear longman & eagle.......you've left me no c...       1  \n",
       "1  Delish. The hubby and I wanted to do brunch on...       5  \n",
       "2  yep, I've giving Yolk 5 stars. It's just reall...       5  \n",
       "3  Meat, meat, meat. It's meat-tastic. So much me...       3  \n",
       "4  I caught up with the law school girls on a Sat...       3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test not useful right now\n",
    "test_meta = pd.read_csv(\"review_meta_test.csv\", sep=\",\", names=[\"label\", \"body_text\"])\n",
    "test_text = pd.read_csv(\"review_meta_train.csv\", sep=',', names=[\"label\", \"body_text\"])\n",
    "\n",
    "# Also not useful right now\n",
    "train_meta = pd.read_csv(\"review_meta_train.csv\", sep=\",\")\n",
    "train_text = pd.read_csv(\"review_text_train.csv\", sep=\",\")\n",
    "\n",
    "# Ids are not predictive. Consider adding in the date?\n",
    "train_meta = train_meta.drop([\"date\", \"review_id\", \"reviewer_id\", \"business_id\"], axis = 1)\n",
    "\n",
    "# Combine the meta features and text. Move class to end\n",
    "train_data = pd.concat([train_meta, train_text], axis=1)\n",
    "class_col = train_data.pop(\"rating\")\n",
    "train_data[\"rating\"] = class_col\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the review text.\n",
    "We want to remove punctuation and numbers, tokenise every review's words, lemmatise the words, then remove all the words in the stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will take extremely long to execute. Might be useful later if we're generating our own features.\n",
    "# Make sure to run once and export to csv\n",
    "# Just use the vectors provided for now\n",
    "\n",
    "punct = string.punctuation\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "# Preprocesses each review in the dataframe\n",
    "def clean_review(review):\n",
    "    # Reassign the string after every change\n",
    "    \n",
    "    # Remove puncutation and numbers\n",
    "    no_punct = ''.join(char for char in review if char not in punct and not char.isdigit())\n",
    "    \n",
    "    # Tokenize into words\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    words = tokenizer.tokenize(no_punct)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    no_stopwords = [wordnet.lemmatize(word) for word in words if word not in stopwords]\n",
    "    \n",
    "    return no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean each review in the dataframe?\n",
    "train_data.loc[:3,\"review\"] = train_data.review.apply(lambda x : clean_review(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use the vectors given to us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR we can just use the preprocessed text data\n",
    "\n",
    "# countvec\n",
    "import pickle\n",
    "vocab = pickle.load(open(\"review_text_features_countvec/train_countvectorizer.pkl\", \"rb\"))\n",
    "vocab_dict = vocab.vocabulary_\n",
    "sparse_matrix_train = scipy.sparse.load_npz(\"review_text_features_countvec/review_text_train_vec.npz\")\n",
    "sparse_matrix_test = scipy.sparse.load_npz(\"review_text_features_countvec/review_text_test_vec.npz\")\n",
    "\n",
    "# doc2vec 50, 100, 200 features vector for training\n",
    "d2v_50_train = pd.read_csv(r\"review_text_features_doc2vec50/review_text_train_doc2vec50.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_100_train = pd.read_csv(r\"review_text_features_doc2vec100/review_text_train_doc2vec100.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_200_train = pd.read_csv(r\"review_text_features_doc2vec200/review_text_train_doc2vec200.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "\n",
    "# doc2vec 50, 100, 200 features vector for testing\n",
    "d2v_50_test = pd.read_csv(r\"review_text_features_doc2vec50/review_text_test_doc2vec50.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_100_test = pd.read_csv(r\"review_text_features_doc2vec100/review_text_test_doc2vec100.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_200_test = pd.read_csv(r\"review_text_features_doc2vec200/review_text_test_doc2vec200.csv\", index_col = False, delimiter = \",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and form train and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, choose which predefined and given vector to use to represent the text data.\n",
    "# Text here is already processed\n",
    "\n",
    "# Function to combine meta features (optional?)  \n",
    "def preprocess(type):\n",
    "    # For each of the doc2vec vectors, concat with meta features\n",
    "    \n",
    "    if type == \"50\":\n",
    "        features = d2v_50_train\n",
    "        train = pd.concat([features.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "        \n",
    "    elif type == \"100\" :\n",
    "        features = d2v_100_train\n",
    "        train = pd.concat([features.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "        \n",
    "    elif type == \"200\" :\n",
    "        features = d2v_200_train\n",
    "        train = pd.concat([features.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "    \n",
    "    # If we chose a doc2vec vector, split and return the training and validation sets\n",
    "    if type != \"count\":\n",
    "        X_train, X_vali, Y_train, Y_vali = train_test_split(train[train.columns[:-1]],\n",
    "                                                        train[\"rating\"], test_size=0.30, random_state=12387)\n",
    "        return X_train, X_vali, Y_train, Y_vali\n",
    "    \n",
    "    # Otherwise do something with the sparse matrix\n",
    "    elif type == \"count\":\n",
    "        X_train, X_vali, Y_train, Y_vali = train_test_split()\n",
    "        return sparse_matrix_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(truthlist, predictions):\n",
    "    # First calculate a crude accuracy score\n",
    "    correct = 0;\n",
    "    wrong = 0;\n",
    "    for i in range(0,len(truthlist)):\n",
    "        if(truthlist[i] == predictions[i]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1;\n",
    "    print(\"The accuracy of the predictions is: {:.5f}\\n\".format(correct/(correct + wrong)))\n",
    "        \n",
    "    # Now construct a confusion matrix of each attribute\n",
    "    truthSeries = pd.Series(truthlist, name = \"Truths\")\n",
    "    predictionSeries = pd.Series(predictions, name = \"Predictions\")\n",
    "    \n",
    "    # Now normalise the confusion matrix so its a percentage of classification performance\n",
    "    confusionDf = pd.crosstab(truthSeries, predictionSeries, rownames=[\"Truths\"], colnames=[\"Predicted\"], margins=False)\n",
    "    confusionDfNormalised = confusionDf / confusionDf.sum(axis=0)\n",
    "    print(\"Confusion Matrix of Correctly Labeled Classes %'s\\n\")\n",
    "    print(confusionDfNormalised)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrained with doc2vec_50 features\u001b[0m\n",
      "The accuracy of the predictions is: 0.72379\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.390013  0.089777  0.037198\n",
      "3          0.333333  0.566684  0.143403\n",
      "5          0.276653  0.343539  0.819399\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mTrained with doc2vec_100 features\u001b[0m\n",
      "The accuracy of the predictions is: 0.68400\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.431849  0.110535  0.057188\n",
      "3          0.232119  0.500778  0.164957\n",
      "5          0.336032  0.388687  0.777855\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mTrained with doc2vec_200 features\u001b[0m\n",
      "The accuracy of the predictions is: 0.64541\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.443995  0.138557  0.079611\n",
      "3          0.140351  0.407369  0.169303\n",
      "5          0.415655  0.454074  0.751086\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category = [\"1\", \"3\", \"5\"]\n",
    "datasets = [\"50\", \"100\", \"200\"] # don't include count for now\n",
    "\n",
    "for i in datasets:\n",
    "    if(i != \"count\"):\n",
    "        print('\\033[1m' + f\"Trained with doc2vec_{i} features\" '\\033[0m')\n",
    "        X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "        clf = GaussianNB().fit(X_train, Y_train)\n",
    "        Y_pred = clf.predict(X_vali)\n",
    "        evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    print('\\033[1m' + f\"Trained with count vectoriser\" '\\033[0m')\n",
    "#    X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "#    clf = GaussianNB().fit(X_train, Y_train)\n",
    "#    Y_pred = clf.predict(X_vali)\n",
    "#    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrained with doc2vec_50 features\u001b[0m\n",
      "The accuracy of the predictions is: 0.77556\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.147099  0.010379  0.000348\n",
      "3          0.464238  0.464453  0.038936\n",
      "5          0.388664  0.525169  0.960716\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mTrained with doc2vec_100 features\u001b[0m\n",
      "The accuracy of the predictions is: 0.80596\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.342780  0.039958  0.003998\n",
      "3          0.390013  0.576544  0.053537\n",
      "5          0.267206  0.383498  0.942465\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mTrained with doc2vec_200 features\u001b[0m\n",
      "The accuracy of the predictions is: 0.82389\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.441296  0.034769  0.003303\n",
      "3          0.333333  0.644006  0.063271\n",
      "5          0.225371  0.321225  0.933426\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in datasets:\n",
    "    print('\\033[1m' + f\"Trained with doc2vec_{i} features\" '\\033[0m')\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
