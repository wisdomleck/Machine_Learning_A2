{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need these\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "#Natural language toolkit. Download if not installed already\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# For splitting by punctuation and using regex\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Useful\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Potentially used Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Evaluation and feature selection tools\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote_funny</th>\n",
       "      <th>vote_cool</th>\n",
       "      <th>vote_useful</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dear longman &amp; eagle.......you've left me no c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Delish. The hubby and I wanted to do brunch on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yep, I've giving Yolk 5 stars. It's just reall...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Meat, meat, meat. It's meat-tastic. So much me...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I caught up with the law school girls on a Sat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vote_funny  vote_cool  vote_useful  \\\n",
       "0           0          1            3   \n",
       "1           0          0            0   \n",
       "2           1          0            1   \n",
       "3          17          3            3   \n",
       "4           0          0            0   \n",
       "\n",
       "                                              review  rating  \n",
       "0  dear longman & eagle.......you've left me no c...       1  \n",
       "1  Delish. The hubby and I wanted to do brunch on...       5  \n",
       "2  yep, I've giving Yolk 5 stars. It's just reall...       5  \n",
       "3  Meat, meat, meat. It's meat-tastic. So much me...       3  \n",
       "4  I caught up with the law school girls on a Sat...       3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test not useful right now\n",
    "test_meta = pd.read_csv(\"review_meta_test.csv\", sep=\",\", names=[\"label\", \"body_text\"])\n",
    "test_text = pd.read_csv(\"review_meta_train.csv\", sep=',', names=[\"label\", \"body_text\"])\n",
    "\n",
    "# Also not useful right now\n",
    "train_meta = pd.read_csv(\"review_meta_train.csv\", sep=\",\")\n",
    "train_text = pd.read_csv(\"review_text_train.csv\", sep=\",\")\n",
    "\n",
    "# Ids are not predictive. Consider adding in the date?\n",
    "train_meta = train_meta.drop([\"date\", \"review_id\", \"reviewer_id\", \"business_id\"], axis = 1)\n",
    "\n",
    "# Combine the meta features and text. Move class to end\n",
    "train_data = pd.concat([train_meta, train_text], axis=1)\n",
    "class_col = train_data.pop(\"rating\")\n",
    "train_data[\"rating\"] = class_col\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the review text. Extension after building models on vectors provided\n",
    "We want to remove punctuation and numbers, tokenise every review's words, lemmatise the words, then remove all the words in the stopwords list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will take extremely long to execute. Might be useful later if we're generating our own features.\n",
    "# Make sure to run once and export to csv\n",
    "# Just use the vectors provided for now\n",
    "\n",
    "punct = string.punctuation\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "# Preprocesses each review in the dataframe\n",
    "def clean_review(review):\n",
    "    # Reassign the string after every change\n",
    "    \n",
    "    # Remove puncutation and numbers\n",
    "    no_punct = ''.join(char for char in review if char not in punct and not char.isdigit())\n",
    "    \n",
    "    # Tokenize into words\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    words = tokenizer.tokenize(no_punct)\n",
    "    \n",
    "    # Remove stopwords and lemmatize, move to lower case\n",
    "    no_stopwords = [wordnet.lemmatize(word).lower() for word in words if word not in stopwords]\n",
    "    \n",
    "    return no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean each review in the dataframe? Takes ~10 mins for all reviews\n",
    "train_data.loc[:1,\"review\"] = train_data.review.apply(lambda x : clean_review(x))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using already preprocessed vectors for the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR we can just use the preprocessed text data\n",
    "\n",
    "# countvec\n",
    "import pickle\n",
    "vocab = pickle.load(open(\"review_text_features_countvec/train_countvectorizer.pkl\", \"rb\"))\n",
    "vocab_dict = vocab.vocabulary_\n",
    "sparse_matrix_train = scipy.sparse.load_npz(\"review_text_features_countvec/review_text_train_vec.npz\")\n",
    "sparse_matrix_test = scipy.sparse.load_npz(\"review_text_features_countvec/review_text_test_vec.npz\")\n",
    "\n",
    "# doc2vec 50, 100, 200 features vector for training\n",
    "d2v_50_train = pd.read_csv(r\"review_text_features_doc2vec50/review_text_train_doc2vec50.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_100_train = pd.read_csv(r\"review_text_features_doc2vec100/review_text_train_doc2vec100.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_200_train = pd.read_csv(r\"review_text_features_doc2vec200/review_text_train_doc2vec200.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "\n",
    "# doc2vec 50, 100, 200 features vector for testing\n",
    "d2v_50_test = pd.read_csv(r\"review_text_features_doc2vec50/review_text_test_doc2vec50.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_100_test = pd.read_csv(r\"review_text_features_doc2vec100/review_text_test_doc2vec100.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_200_test = pd.read_csv(r\"review_text_features_doc2vec200/review_text_test_doc2vec200.csv\", index_col = False, delimiter = \",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and form train and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, choose which predefined and given vector to use to represent the text data.\n",
    "# Text here is already processed\n",
    "\n",
    "# Function to combine meta features (optional?)  \n",
    "def preprocess(type, randomstate = 12587):\n",
    "    # For each of the doc2vec vectors, concat with meta features\n",
    "    \n",
    "    if type == \"50\":\n",
    "        features = d2v_50_train\n",
    "        train = pd.concat([features.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "        \n",
    "    elif type == \"100\" :\n",
    "        features = d2v_100_train\n",
    "        train = pd.concat([features.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "        \n",
    "    elif type == \"200\" :\n",
    "        features = d2v_200_train\n",
    "        train = pd.concat([features.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "    \n",
    "    # If we chose a doc2vec vector, split and return the training and validation sets\n",
    "    if type != \"count\":\n",
    "        # Above concat method causes duplicating index column\n",
    "        train = train.loc[:,~train.columns.duplicated()]\n",
    "        \n",
    "        X_train, X_vali, Y_train, Y_vali = train_test_split(train[train.columns[:-1]],\n",
    "                                                        train[\"rating\"], test_size=0.30, random_state=randomstate)\n",
    "        return X_train, X_vali, Y_train, Y_vali\n",
    "    \n",
    "    # Otherwise do something with the sparse matrix\n",
    "    elif type == \"count\":\n",
    "        X_train, X_vali, Y_train, Y_vali = train_test_split(sparse_matrix_train, \n",
    "                                                            train_data[\"rating\"], test_size=0.30, random_state=randomstate)\n",
    "        return X_train, X_vali, Y_train, Y_vali\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and train models and Crudely evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crude accuracy score and confusion matrix of predictions with % correct. Matrix is \"Predicted label x for an instance\n",
    "# with Class label y\"\n",
    "\n",
    "def evaluate(truthlist, predictions):\n",
    "    # First calculate a crude accuracy score\n",
    "    correct = 0;\n",
    "    wrong = 0;\n",
    "    for i in range(0,len(truthlist)):\n",
    "        if(truthlist[i] == predictions[i]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1;\n",
    "    print(\"The accuracy of the predictions is: {:.5f}\\n\".format(correct/(correct + wrong)))\n",
    "        \n",
    "    # Now construct a confusion matrix of each attribute\n",
    "    truthSeries = pd.Series(truthlist, name = \"Truths\")\n",
    "    predictionSeries = pd.Series(predictions, name = \"Predictions\")\n",
    "    \n",
    "    # Now normalise the confusion matrix so its a percentage of classification performance\n",
    "    confusionDf = pd.crosstab(truthSeries, predictionSeries, rownames=[\"Truths\"], colnames=[\"Predicted\"], margins=False)\n",
    "    confusionDfNormalised = confusionDf / confusionDf.sum(axis=0)\n",
    "    print(\"Confusion Matrix of Correctly Labeled Classes %'s\\n\")\n",
    "    print(confusionDfNormalised)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "import csv\n",
    "\n",
    "# Also need a function to export the predictions to a CSV\n",
    "def export(instanceid, predictions):\n",
    "    f = open(\"output.csv\", \"w\", newline='')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Instance_id\", \"rating\"])\n",
    "    \n",
    "    for i, j in zip(instanceid, predictions):\n",
    "        f.write(str(i) + \",\" + str(j))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = [\"1\", \"3\", \"5\"]\n",
    "datasets = [\"50\", \"100\", \"200\", \"count\"] # don't include count for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial Naive Bayes\n",
    "Binomial NB would only work for discrete data. Possibly discretise doc2vec vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m' + f\"Trained with count vectoriser\" '\\033[0m')\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "clf = BernoulliNB().fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_vali)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive bayes\n",
    "Probably use the doc2vec continuous vectors for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    if(i != \"count\"):\n",
    "        print('\\033[1m' + f\"Trained with doc2vec_{i} features\" '\\033[0m')\n",
    "        X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "        clf = GaussianNB().fit(X_train, Y_train)\n",
    "        Y_pred = clf.predict(X_vali)\n",
    "        evaluate(Y_pred, Y_vali.values)\n",
    "    else:\n",
    "        print(\"Haven't used count vector for GNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive bayes\n",
    "Same with binomial Nb. Use the countvector, or discretise the continuous data in doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m' + f\"Trained with count vectoriser\" '\\033[0m')\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_vali)\n",
    "evaluate(Y_pred, Y_vali.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "works and runs for all of the vectors provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    print('\\033[1m' + f\"Trained with doc2vec_{i} features\" '\\033[0m')\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each SVM Takes around 15-20 minutes to run...\n",
    "for i in datasets:\n",
    "    print(f\"Training using doc2vec_{i} data set\")\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = LinearSVC(max_iter=5000).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC with Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "\n",
    "for i in datasets:\n",
    "    print(f\"Training using doc2vec_{i} data set\")\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = SVC(kernel='linear', C=C).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    print(f\"Training using doc2vec_{i} data set\")\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = SVC(kernel='rbf', gamma=0.7, C=C).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC with poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    print(f\"Training using doc2vec_{i} data set\")\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = SVC(kernel='poly', degree=3, gamma='auto', C=1.0).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    print(f\"Training using doc2vec_{i} data set\")\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = RandomForestClassifier(n_estimators=100).fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    print(f\"Training using doc2vec_{i} data set\")\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "    clf = DecisionTreeClassifier(max_depth=None, criterion=\"entropy\").fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_vali)\n",
    "    evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using feature selection via chi^2, MI\n",
    "Marginally increases performance. Possibly due to logisitc regression already weighting good features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "x2 = SelectKBest(chi2, k=2000)\n",
    "\n",
    "X_train_x2 = x2.fit_transform(X_train, Y_train)\n",
    "X_vali_x2 = x2.transform(X_vali)\n",
    "\n",
    "print('\\033[1m' + f\"Trained with COUNT features\" '\\033[0m')\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000).fit(X_train_x2, Y_train)\n",
    "Y_pred = clf.predict(X_vali_x2)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"200\")\n",
    "\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=80)\n",
    "mi.fit(X_train, Y_train)\n",
    "X_train_mi = mi.transform(X_train)\n",
    "X_test_mi = mi.transform(X_vali)\n",
    "\n",
    "print('\\033[1m' + f\"Trained with COUNT features\" '\\033[0m')\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000).fit(X_train_mi, Y_train)\n",
    "Y_pred = clf.predict(X_test_mi)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest with feature selection, via chi^2, MI\n",
    "Increases performance by 2-4% with some k settings on the doc2vecs and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Training using doc2vec_count data set\")\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "    \n",
    "x2 = SelectKBest(chi2, k=500)\n",
    "X_train_x2 = x2.fit_transform(X_train, Y_train)\n",
    "X_vali_x2 = x2.transform(X_vali)\n",
    "    \n",
    "clf = RandomForestClassifier(n_estimators=100).fit(X_train_x2, Y_train)\n",
    "Y_pred = clf.predict(X_vali_x2)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training using doc2vec_50 data set\")\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"50\")\n",
    "\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=25)\n",
    "mi.fit(X_train, Y_train)\n",
    "X_train_mi = mi.transform(X_train)\n",
    "X_test_mi = mi.transform(X_vali)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100).fit(X_train_mi, Y_train)\n",
    "Y_pred = clf.predict(X_test_mi)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVMs with a reduced dataset, using feature selection chi2, MI. \n",
    "Lets us run SVM classifiers in reasonable time by using a reduced feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can reduce the time?\n",
    "print(f\"Training using doc2vec_100 data set\")\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"100\")\n",
    "    \n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=40)\n",
    "mi.fit(X_train, Y_train)\n",
    "X_train_mi = mi.transform(X_train)\n",
    "X_test_mi = mi.transform(X_vali)\n",
    "    \n",
    "clf = LinearSVC(max_iter=5000).fit(X_train_mi, Y_train)\n",
    "Y_pred = clf.predict(X_test_mi)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training using doc2vec_200 data set\")\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"200\")\n",
    "\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=50)\n",
    "mi.fit(X_train, Y_train)\n",
    "X_train_mi = mi.transform(X_train)\n",
    "X_test_mi = mi.transform(X_vali)\n",
    "\n",
    "clf = SVC(kernel='poly', degree=3, gamma='auto', C=1.0).fit(X_train_mi, Y_train)\n",
    "Y_pred = clf.predict(X_test_mi)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training using doc2vec_200 data set\")\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"200\")\n",
    "\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=50)\n",
    "mi.fit(X_train, Y_train)\n",
    "X_train_mi = mi.transform(X_train)\n",
    "X_test_mi = mi.transform(X_vali)\n",
    "\n",
    "clf = SVC(kernel='rbf', degree=3, gamma='auto', C=1.0).fit(X_train_mi, Y_train)\n",
    "Y_pred = clf.predict(X_test_mi)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try use some boosting models now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each SVM Takes around 15-20 minutes to run...\n",
    "for i in datasets:\n",
    "    if(i != \"count\"):\n",
    "        print(f\"Training using doc2vec_{i} with XGBoost\")\n",
    "        X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "        clf = XGBClassifier().fit(X_train, Y_train)\n",
    "        Y_pred = clf.predict(X_vali)\n",
    "        evaluate(Y_pred, Y_vali.values)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training using doc2vec_count with XGBoost\")\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "clf = XGBClassifier().fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_vali)\n",
    "evaluate(Y_pred, Y_vali.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try stacking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X)\n",
    "        self.metaclassifier.fit(X_meta, y)\n",
    "    \n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        assert yhats.shape[0] == X.shape[0]\n",
    "        return yhats\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)     \n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)\n",
    "    \n",
    "\n",
    "\n",
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                MultinomialNB(),\n",
    "                #XGBClassifier(),\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB',\n",
    "          #'XGBoost',\n",
    "          #'Linear SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"100\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random stacking sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                MultinomialNB(),\n",
    "                XGBClassifier(),\n",
    "                SVC(kernel='linear', C=1.0, probability=True),\n",
    "                SVC(kernel='rbf', gamma=0.7, C=1.0),\n",
    "                SVC(kernel='poly', degree=3, gamma='auto', C=1.0),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB',\n",
    "          'XGBoost',\n",
    "          'Linear SVC kernel',\n",
    "          'RBF SVC kernel',\n",
    "          'Poly SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                MultinomialNB(),\n",
    "                XGBClassifier(),\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                #SVC(kernel='rbf', gamma=0.7, C=C, probability=True),\n",
    "                SVC(kernel='poly', degree=3, gamma='auto', C=1.0, probability=True),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB',\n",
    "          'XGBoost',\n",
    "          #'Linear SVC kernel',\n",
    "          #'RBF SVC kernel',\n",
    "          'Poly SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                MultinomialNB(),\n",
    "                XGBClassifier()\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                #SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "                #SVC(kernel='poly', degree=3, gamma='auto', C=1.0),\n",
    "                #RandomForestClassifier(n_estimators=100)]\n",
    "              ]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB',\n",
    "          'XGBoost'\n",
    "          #'Linear SVC kernel',\n",
    "          #'RBF SVC kernel',\n",
    "          #'Poly SVC kernel',\n",
    "          #'Forest'\n",
    "         ]\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                #MultinomialNB(),\n",
    "                XGBClassifier(),\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                SVC(kernel='rbf', gamma=0.7, C=1.0, probability=True),\n",
    "                #SVC(kernel='poly', degree=3, gamma='auto', C=1.0),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          #'Multinomial NB',\n",
    "          'XGBoost',\n",
    "          #'Linear SVC kernel',\n",
    "          'RBF SVC kernel',\n",
    "          #'Poly SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                MultinomialNB(),\n",
    "                XGBClassifier(),\n",
    "                SVC(kernel='linear', C=1.0, probability=True),\n",
    "                #SVC(kernel='rbf', gamma=0.7, C=1.0, probability=True),\n",
    "                #SVC(kernel='poly', degree=3, gamma='auto', C=1.0, probability=True),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB',\n",
    "          'XGBoost',\n",
    "          'Linear SVC kernel',\n",
    "          #'RBF SVC kernel',\n",
    "          #'Poly SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                #MultinomialNB(),\n",
    "                XGBClassifier(),\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                #SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "                SVC(kernel='poly', degree=3, gamma='auto', C=1.0, probability=True)\n",
    "                #RandomForestClassifier(n_estimators=100)]\n",
    "              ]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          #'Multinomial NB',\n",
    "          'XGBoost',\n",
    "          #'Linear SVC kernel',\n",
    "          #'RBF SVC kernel',\n",
    "          'Poly SVC kernel'\n",
    "          #'Forest']\n",
    "         ]\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                MultinomialNB(),\n",
    "                #XGBClassifier(),\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "                #SVC(kernel='poly', degree=3, gamma='auto', C=1.0),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          'Multinomial NB',\n",
    "          #'XGBoost',\n",
    "          #'Linear SVC kernel',\n",
    "          'RBF SVC kernel',\n",
    "          #'Poly SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "\n",
    "X_train, X_vali, Y_train, Y_vali = preprocess(\"count\")\n",
    "\n",
    "for title,clf in zip(titles,classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "    \n",
    "stacker.fit(X_train, Y_train)\n",
    "print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "                #MultinomialNB(),\n",
    "                XGBClassifier(),\n",
    "                #SVC(kernel='linear', C=1.0, probability=True),\n",
    "                #SVC(kernel='rbf', gamma=0.7, C=1.0, probability=True),\n",
    "                SVC(kernel='poly', degree=3, gamma='auto', C=1.0),\n",
    "                RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "titles = ['Logistic Regression',\n",
    "          #'Multinomial NB',\n",
    "          'XGBoost',\n",
    "          #'Linear SVC kernel',\n",
    "          #'RBF SVC kernel',\n",
    "          'Poly SVC kernel',\n",
    "          'Forest']\n",
    "\n",
    "meta_classifier = LogisticRegression(solver='lbfgs')\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "for i in datasets:\n",
    "    X_train, X_vali, Y_train, Y_vali = preprocess(i)\n",
    "\n",
    "    for title,clf in zip(titles,classifiers):\n",
    "        clf.fit(X_train, Y_train)\n",
    "        print(title, \"Accuracy:\",clf.score(X_vali, Y_vali))\n",
    "\n",
    "    stacker.fit(X_train, Y_train)\n",
    "    print('\\nStacker Accuracy:', stacker.score(X_vali, Y_vali))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
