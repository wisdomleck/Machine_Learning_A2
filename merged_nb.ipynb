{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [EDA](#EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need these\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Natural language toolkit. Download if not installed already\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# For splitting by punctuation and using regex\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Useful\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Potentially used Models\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Evaluation and feature selection tools\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "\n",
    "#benchmark\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in train and test data\n",
    "\n",
    "meta_train_df = pd.read_csv(\"review_meta_train.csv\")\n",
    "text_train_df = pd.read_csv(\"review_text_train.csv\")\n",
    "train_data = pd.concat([text_train_df, meta_train_df], axis=1)\n",
    "\n",
    "meta_test_df = pd.read_csv(\"review_meta_test.csv\")\n",
    "text_test_df = pd.read_csv(\"review_text_test.csv\")\n",
    "test_data = pd.concat([text_test_df, meta_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>vote_funny</th>\n",
       "      <th>vote_cool</th>\n",
       "      <th>vote_useful</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear longman &amp; eagle.......you've left me no c...</td>\n",
       "      <td>3/15/2012</td>\n",
       "      <td>-s77HISu8DVQ8F0HxmWW6A</td>\n",
       "      <td>mthr7h15a_z9m9jRI6mG6Q</td>\n",
       "      <td>m5_GCJP2W4zEJnyVgxa3eA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delish. The hubby and I wanted to do brunch on...</td>\n",
       "      <td>6/21/2010</td>\n",
       "      <td>A2aCzGCgg6gAbatHiCrPfA</td>\n",
       "      <td>rhM01fl3iU0xHr3TIpCMhQ</td>\n",
       "      <td>m5_GCJP2W4zEJnyVgxa3eA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yep, I've giving Yolk 5 stars. It's just reall...</td>\n",
       "      <td>7/29/2011</td>\n",
       "      <td>DK2pd</td>\n",
       "      <td>SNHKDgmGiLn5chUlhdLCkg</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meat, meat, meat. It's meat-tastic. So much me...</td>\n",
       "      <td>3/10/2006</td>\n",
       "      <td>b3BkUiWJEKNQko</td>\n",
       "      <td>HXjk1RVfLMPeZxitnk1Auw</td>\n",
       "      <td>43rd1LKcZRIunySzbMsyLQ</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I caught up with the law school girls on a Sat...</td>\n",
       "      <td>8/28/2012</td>\n",
       "      <td>RabHhte</td>\n",
       "      <td>W0ny0BqO0OJ4K4aVnSIlBw</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review       date  \\\n",
       "0  dear longman & eagle.......you've left me no c...  3/15/2012   \n",
       "1  Delish. The hubby and I wanted to do brunch on...  6/21/2010   \n",
       "2  yep, I've giving Yolk 5 stars. It's just reall...  7/29/2011   \n",
       "3  Meat, meat, meat. It's meat-tastic. So much me...  3/10/2006   \n",
       "4  I caught up with the law school girls on a Sat...  8/28/2012   \n",
       "\n",
       "                review_id             reviewer_id             business_id  \\\n",
       "0  -s77HISu8DVQ8F0HxmWW6A  mthr7h15a_z9m9jRI6mG6Q  m5_GCJP2W4zEJnyVgxa3eA   \n",
       "1  A2aCzGCgg6gAbatHiCrPfA  rhM01fl3iU0xHr3TIpCMhQ  m5_GCJP2W4zEJnyVgxa3eA   \n",
       "2                   DK2pd  SNHKDgmGiLn5chUlhdLCkg  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "3          b3BkUiWJEKNQko  HXjk1RVfLMPeZxitnk1Auw  43rd1LKcZRIunySzbMsyLQ   \n",
       "4                 RabHhte  W0ny0BqO0OJ4K4aVnSIlBw  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "\n",
       "   vote_funny  vote_cool  vote_useful  rating  \n",
       "0           0          1            3       1  \n",
       "1           0          0            0       5  \n",
       "2           1          0            1       5  \n",
       "3          17          3            3       3  \n",
       "4           0          0            0       3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec 50, 100, 200 features vector for training\n",
    "d2v_50_train = pd.read_csv(r\"review_text_features_doc2vec50/review_text_train_doc2vec50.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_100_train = pd.read_csv(r\"review_text_features_doc2vec100/review_text_train_doc2vec100.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_200_train = pd.read_csv(r\"review_text_features_doc2vec200/review_text_train_doc2vec200.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "\n",
    "# doc2vec 50, 100, 200 features vector for testing\n",
    "d2v_50_test = pd.read_csv(r\"review_text_features_doc2vec50/review_text_test_doc2vec50.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_100_test = pd.read_csv(r\"review_text_features_doc2vec100/review_text_test_doc2vec100.csv\", index_col = False, delimiter = \",\", header=None)\n",
    "d2v_200_test = pd.read_csv(r\"review_text_features_doc2vec200/review_text_test_doc2vec200.csv\", index_col = False, delimiter = \",\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets take a quick look at the class labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    19288\n",
      "3     6444\n",
      "1     2336\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 5 stars is by far the most popular class. Potentially could look to undersample class 5 or oversample classes 1 and 3 when training the data. Otherwise, the learner might get lazy and select the majority class too often. As a benchmark, we can look to outperform the ZeroR classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroR accuracy is 0.6872...\n"
     ]
    }
   ],
   "source": [
    "zeroR = DummyClassifier(strategy = \"most_frequent\")\n",
    "zeroR.fit(train_data.rating, train_data.rating)\n",
    "score = zeroR.score(train_data.rating, train_data.rating)\n",
    "print(\"zeroR accuracy is {:.4f}...\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploration of the meta data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count  rating\n",
       "0       1   15777\n",
       "1       2    2596\n",
       "2       3     805\n",
       "3       4     364\n",
       "4       5     208\n",
       "5       6     103\n",
       "6       7      74\n",
       "7       8      37\n",
       "8       9      24\n",
       "9      10      11\n",
       "10     11       8\n",
       "11     12       7\n",
       "12     15       5\n",
       "13     16       4\n",
       "14     14       3\n",
       "15     13       3\n",
       "16     19       2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_value_counts = train_data.groupby(['reviewer_id'])['rating'].count().reset_index().rating.value_counts()\n",
    "rating_value_counts = rating_value_counts.reset_index().rename(columns = {\"index\": \"count\"})\n",
    "rating_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x236a8f05488>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rating_value_counts[\"count\"], rating_value_counts[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vast majority of reviewers have either 1 or 2 reviews... However, some reviewers have multiple reviews. This could be a useful feature to detect some edge cases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the vote counts into percentage votes \n",
    "\n",
    "votes = ['vote_funny', 'vote_cool', 'vote_useful']\n",
    "# votes_df = train_data[['vote_funny', 'vote_cool', 'vote_useful', 'rating']]\n",
    "train_data['total_votes'] = train_data['vote_funny'] + train_data['vote_cool'] + train_data['vote_useful']\n",
    "\n",
    "for vote in votes:\n",
    "    percentage_votes = 'percentage_' + vote\n",
    "    train_data[percentage_votes] = train_data[vote] / train_data['total_votes']\n",
    "    \n",
    "train_data = train_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>percentage_vote_funny</th>\n",
       "      <th>percentage_vote_cool</th>\n",
       "      <th>percentage_vote_useful</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.051008</td>\n",
       "      <td>0.289528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.088423</td>\n",
       "      <td>0.260617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.075794</td>\n",
       "      <td>0.130812</td>\n",
       "      <td>0.214226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       percentage_vote_funny percentage_vote_cool percentage_vote_useful\n",
       "                        mean                 mean                   mean\n",
       "rating                                                                  \n",
       "1                   0.142341             0.051008               0.289528\n",
       "3                   0.088110             0.088423               0.260617\n",
       "5                   0.075794             0.130812               0.214226"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['rating']).agg(\n",
    "    {\n",
    "        'percentage_vote_funny': ['mean'], \n",
    "        'percentage_vote_cool': ['mean'],\n",
    "        'percentage_vote_useful': ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be directionality between the mean percentage votes and the rating someone is given... Perhaps this could be useful in cases where a machine learning algorithm cannot detect sarcasm by itself. Lets look at some of these funny reviews as an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"snooze-a-roo. I ordered some breakfast sandwich, and when it showed up, it was just a croissant with two strips of bacon on it and nothing else, so fifteen minutes later when the waitress came back and I complained, she brought me a plate with the other stuff that was supposed to come on it. It cost 12 dollars and the wait is a half hour to be smashed in a corner where there is nowhere to put your winter coat. I can't understand the appeal of this place. I would recommend that folks try anything else for breakfast. Maybe a donkey punch or a dirty sanchez would be more satisfying.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[(train_data.rating == 1) & (train_data.percentage_vote_funny > 0.5)].reset_index().iloc[0].review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author is being sarcastic \"Maybe a donkey punch or a dirty sanchez would be more satisfying\" but you would also expect this review to receive a negative rating..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about data? are critics getting harsher over time, or is there another trend we are able to detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['date'] = pd.to_datetime(train_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['year'] = train_data['date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>4.580000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>4.360902</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>4.256887</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4.159780</td>\n",
       "      <td>2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4.197502</td>\n",
       "      <td>4324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4.225112</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>4.212743</td>\n",
       "      <td>7314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>4.174741</td>\n",
       "      <td>4830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating      \n",
       "          mean count\n",
       "year                \n",
       "2004  5.000000     4\n",
       "2005  4.580000   100\n",
       "2006  4.360902   532\n",
       "2007  4.256887  1561\n",
       "2008  4.159780  2904\n",
       "2009  4.197502  4324\n",
       "2010  4.225112  6499\n",
       "2011  4.212743  7314\n",
       "2012  4.174741  4830"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['year']).agg({'rating': ['mean', 'count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do critics get harsher over time? or perhaps do movies get worse??? or maybe its just due to the small sample size in years 2004 and 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "consider in countvectoriser: not using stopwords param, adding lemmatizer param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here, choose which predefined and given vector to use to represent the text data.\n",
    "# # Text here is already processed\n",
    "\n",
    "# d2vtrain = [d2v_50_train, d2v_100_train, d2v_200_train]\n",
    "# d2v_50_train.name = \"d2v_50\"\n",
    "# d2v_100_train.name = \"d2v_100\"\n",
    "# d2v_200_train.name = \"d2v_200\"\n",
    "\n",
    "# # Function to split a doc2Vec vector into training and testing\n",
    "# def splitDoc2Vec(doc, randomstate = 8579):\n",
    "#     # For each of the doc2vec vectors, concat with meta features\n",
    "#     train = doc\n",
    "#     train = pd.concat([train.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "    \n",
    "#     # Above concat method causes duplicating index column\n",
    "#     train = train.loc[:,~train.columns.duplicated()]\n",
    "#     train = train.drop(columns = ['index'])\n",
    "    \n",
    "#     # Split into training and validation sets\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(train[train.columns[:-1]],\n",
    "#                                                         train[\"rating\"], test_size=0.20, random_state=randomstate)\n",
    "#     return X_train, X_test, Y_train, np.array(Y_test)\n",
    "\n",
    "# # Function to split the given sparse matrix into training and testing\n",
    "# def splitSparse(randomstate = 8579):\n",
    "#     X_train, X_vali, Y_train, Y_vali = train_test_split(sparse_matrix_train, \n",
    "#                                                             train_data[\"rating\"], test_size=0.20, random_state=randomstate)\n",
    "#     return X_train, X_vali, Y_train, np.array(Y_vali)\n",
    "\n",
    "# # Function to split the training data into train and test, but first vectorising the reviews\n",
    "# def splitVectorised(ngram_range = (1,1), randomstate = 8579):\n",
    "#     # Split the reviews and ratings\n",
    "#     X_train, X_vali, Y_train, y_vali = train_test_split(train_data[\"review\"], train_data[\"rating\"], test_size=0.20, random_state=randomstate)\n",
    "#     X_train_txt, y_train = np.array(X_train), np.array(X_train)\n",
    "#     X_test_txt, y_test = np.array(X_vali), np.array(y_vali)\n",
    "        \n",
    "#     # vectorise the reviews\n",
    "#     vectoriser = CountVectorizer(ngram_range=ngram_range) #optional stop_words = 'english', tokenizer=LemmaTokenizer()\n",
    "#     vectoriser.fit(X_train_txt)\n",
    "#     X_train = vectoriser.transform(X_train_txt)\n",
    "#     X_test = vectoriser.transform(X_test_txt)\n",
    "    \n",
    "#     # Need to return vectoriser fit external test set\n",
    "#     return X_train, X_test, Y_train, y_test, vectoriser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run classifiers using a single train test split to get some crude results. Cross validation comes later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crude accuracy score and confusion matrix of predictions with % correct. Matrix is \"Predicted label x for an instance\n",
    "# # with Class label y\"\n",
    "\n",
    "# def evaluate(truthlist, predictions):\n",
    "#     # First calculate a crude accuracy score\n",
    "#     correct = 0;\n",
    "#     wrong = 0;\n",
    "#     for i in range(0,len(truthlist)):\n",
    "#         if(truthlist[i] == predictions[i]):\n",
    "#             correct += 1\n",
    "#         else:\n",
    "#             wrong += 1;\n",
    "#     print(\"The accuracy of the predictions is: {:.5f}\\n\".format(correct/(correct + wrong)))\n",
    "        \n",
    "#     # Now construct a confusion matrix of each attribute\n",
    "#     truthSeries = pd.Series(truthlist, name = \"Truths\")\n",
    "#     predictionSeries = pd.Series(predictions, name = \"Predictions\")\n",
    "    \n",
    "#     # Now normalise the confusion matrix so its a percentage of classification performance\n",
    "#     confusionDf = pd.crosstab(truthSeries, predictionSeries, rownames=[\"Truths\"], colnames=[\"Predicted\"], margins=False)\n",
    "#     confusionDfNormalised = confusionDf / confusionDf.sum(axis=0)\n",
    "#     print(\"Confusion Matrix of Correctly Labeled Classes %'s\\n\")\n",
    "#     print(confusionDfNormalised)\n",
    "#     print(\"\\n\\n\")\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizer if wanted in countvectoriser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>vote_funny</th>\n",
       "      <th>vote_cool</th>\n",
       "      <th>vote_useful</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>percentage_vote_funny</th>\n",
       "      <th>percentage_vote_cool</th>\n",
       "      <th>percentage_vote_useful</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear longman &amp; eagle.......you've left me no c...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>-s77HISu8DVQ8F0HxmWW6A</td>\n",
       "      <td>mthr7h15a_z9m9jRI6mG6Q</td>\n",
       "      <td>m5_GCJP2W4zEJnyVgxa3eA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delish. The hubby and I wanted to do brunch on...</td>\n",
       "      <td>2010-06-21</td>\n",
       "      <td>A2aCzGCgg6gAbatHiCrPfA</td>\n",
       "      <td>rhM01fl3iU0xHr3TIpCMhQ</td>\n",
       "      <td>m5_GCJP2W4zEJnyVgxa3eA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yep, I've giving Yolk 5 stars. It's just reall...</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>DK2pd</td>\n",
       "      <td>SNHKDgmGiLn5chUlhdLCkg</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meat, meat, meat. It's meat-tastic. So much me...</td>\n",
       "      <td>2006-03-10</td>\n",
       "      <td>b3BkUiWJEKNQko</td>\n",
       "      <td>HXjk1RVfLMPeZxitnk1Auw</td>\n",
       "      <td>43rd1LKcZRIunySzbMsyLQ</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I caught up with the law school girls on a Sat...</td>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>RabHhte</td>\n",
       "      <td>W0ny0BqO0OJ4K4aVnSIlBw</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review       date  \\\n",
       "0  dear longman & eagle.......you've left me no c... 2012-03-15   \n",
       "1  Delish. The hubby and I wanted to do brunch on... 2010-06-21   \n",
       "2  yep, I've giving Yolk 5 stars. It's just reall... 2011-07-29   \n",
       "3  Meat, meat, meat. It's meat-tastic. So much me... 2006-03-10   \n",
       "4  I caught up with the law school girls on a Sat... 2012-08-28   \n",
       "\n",
       "                review_id             reviewer_id             business_id  \\\n",
       "0  -s77HISu8DVQ8F0HxmWW6A  mthr7h15a_z9m9jRI6mG6Q  m5_GCJP2W4zEJnyVgxa3eA   \n",
       "1  A2aCzGCgg6gAbatHiCrPfA  rhM01fl3iU0xHr3TIpCMhQ  m5_GCJP2W4zEJnyVgxa3eA   \n",
       "2                   DK2pd  SNHKDgmGiLn5chUlhdLCkg  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "3          b3BkUiWJEKNQko  HXjk1RVfLMPeZxitnk1Auw  43rd1LKcZRIunySzbMsyLQ   \n",
       "4                 RabHhte  W0ny0BqO0OJ4K4aVnSIlBw  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "\n",
       "   vote_funny  vote_cool  vote_useful  rating  total_votes  \\\n",
       "0           0          1            3       1            4   \n",
       "1           0          0            0       5            0   \n",
       "2           1          0            1       5            2   \n",
       "3          17          3            3       3           23   \n",
       "4           0          0            0       3            0   \n",
       "\n",
       "   percentage_vote_funny  percentage_vote_cool  percentage_vote_useful  year  \n",
       "0                0.00000              0.250000                0.750000  2012  \n",
       "1                0.00000              0.000000                0.000000  2010  \n",
       "2                0.50000              0.000000                0.500000  2011  \n",
       "3                0.73913              0.130435                0.130435  2006  \n",
       "4                0.00000              0.000000                0.000000  2012  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.review\n",
    "y = train_data.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by training individual classifiers..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "MNB runs ~84% with ngrams (1,1). ~72% with ngrams(1,2), ~69% with ngrams (1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=None, param_grid={'alpha': [0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha': [0.1, 1]} \n",
    "mnb = MultinomialNB()\n",
    "mnb_grid = GridSearchCV(mnb, params)\n",
    "mnb_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0146</td>\n",
       "      <td>4.899014e-04</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.822943</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.821308</td>\n",
       "      <td>0.823980</td>\n",
       "      <td>0.822324</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0150</td>\n",
       "      <td>2.780415e-07</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.832918</td>\n",
       "      <td>0.841646</td>\n",
       "      <td>0.842358</td>\n",
       "      <td>0.836273</td>\n",
       "      <td>0.834135</td>\n",
       "      <td>0.837466</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0         0.0146  4.899014e-04         0.002198        0.000396         0.1   \n",
       "1         0.0150  2.780415e-07         0.002400        0.000490           1   \n",
       "\n",
       "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.1}           0.822943           0.819202           0.824190   \n",
       "1    {'alpha': 1}           0.832918           0.841646           0.842358   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.821308           0.823980         0.822324        0.001865   \n",
       "1           0.836273           0.834135         0.837466        0.003863   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(mnb_grid.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    {'alpha': 1}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.loc[cv_results.rank_test_score == 1].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train the mnb classifier using all the data and these hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha = 1)\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinominal naive bayes accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x236ab5908c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = mnb.predict(X_test)\n",
    "score = mnb.score(X_test, y_test)\n",
    "print(\"multinominal naive bayes accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(mnb, X_test, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [1000000],\n",
       "                         'penalty': ['l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.01, 0.1 , 1, 10],\n",
    "    'max_iter': [1000000]\n",
    "} \n",
    "logreg = LogisticRegression()\n",
    "logreg_grid = GridSearchCV(logreg, params)\n",
    "logreg_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.329106</td>\n",
       "      <td>0.032185</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 1000000, 'penalty': 'l2'}</td>\n",
       "      <td>0.826327</td>\n",
       "      <td>0.834165</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.826831</td>\n",
       "      <td>0.838055</td>\n",
       "      <td>0.831196</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.990651</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 1000000, 'penalty': 'l2'}</td>\n",
       "      <td>0.840933</td>\n",
       "      <td>0.846633</td>\n",
       "      <td>0.846455</td>\n",
       "      <td>0.848210</td>\n",
       "      <td>0.851595</td>\n",
       "      <td>0.846765</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.517355</td>\n",
       "      <td>0.226727</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'max_iter': 1000000, 'penalty': 'l2'}</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.840221</td>\n",
       "      <td>0.836124</td>\n",
       "      <td>0.837342</td>\n",
       "      <td>0.844468</td>\n",
       "      <td>0.837751</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.587533</td>\n",
       "      <td>0.344698</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'max_iter': 1000000, 'penalty': 'l2'}</td>\n",
       "      <td>0.816352</td>\n",
       "      <td>0.821696</td>\n",
       "      <td>0.818133</td>\n",
       "      <td>0.822020</td>\n",
       "      <td>0.828078</td>\n",
       "      <td>0.821256</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.329106      0.032185         0.002800        0.000400    0.01   \n",
       "1       2.990651      0.135104         0.002803        0.000401     0.1   \n",
       "2       6.517355      0.226727         0.002795        0.000398       1   \n",
       "3      10.587533      0.344698         0.002998        0.000005      10   \n",
       "\n",
       "  param_max_iter param_penalty  \\\n",
       "0        1000000            l2   \n",
       "1        1000000            l2   \n",
       "2        1000000            l2   \n",
       "3        1000000            l2   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'C': 0.01, 'max_iter': 1000000, 'penalty': 'l2'}           0.826327   \n",
       "1   {'C': 0.1, 'max_iter': 1000000, 'penalty': 'l2'}           0.840933   \n",
       "2     {'C': 1, 'max_iter': 1000000, 'penalty': 'l2'}           0.830602   \n",
       "3    {'C': 10, 'max_iter': 1000000, 'penalty': 'l2'}           0.816352   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.834165           0.830602           0.826831           0.838055   \n",
       "1           0.846633           0.846455           0.848210           0.851595   \n",
       "2           0.840221           0.836124           0.837342           0.844468   \n",
       "3           0.821696           0.818133           0.822020           0.828078   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.831196        0.004449                3  \n",
       "1         0.846765        0.003451                1  \n",
       "2         0.837751        0.004586                2  \n",
       "3         0.821256        0.004028                4  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(logreg_grid.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    {'C': 0.1, 'max_iter': 1000000, 'penalty': 'l2'}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.loc[cv_results.rank_test_score == 1].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train the mnb classifier using all the data and these hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 0.1, max_iter = 1000000, penalty = 'l2')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinominal naive bayes accuracy: 0.8463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x236b1864188>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "score = logreg.score(X_test, y_test)\n",
    "print(\"multinominal naive bayes accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(logreg, X_test, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the class labels are imbalanced, lets try undersampling/oversampling the training data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 0.1, max_iter = 1000000, penalty = 'l2')\n",
    "logreg.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy: 0.7893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x236be293548>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "score = logreg.score(X_test, y_test)\n",
    "print(\"logistic regression accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(logreg, X_test, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>vote_funny</th>\n",
       "      <th>vote_cool</th>\n",
       "      <th>vote_useful</th>\n",
       "      <th>rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>percentage_vote_funny</th>\n",
       "      <th>percentage_vote_cool</th>\n",
       "      <th>percentage_vote_useful</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear longman &amp; eagle.......you've left me no c...</td>\n",
       "      <td>2012-03-15</td>\n",
       "      <td>-s77HISu8DVQ8F0HxmWW6A</td>\n",
       "      <td>mthr7h15a_z9m9jRI6mG6Q</td>\n",
       "      <td>m5_GCJP2W4zEJnyVgxa3eA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delish. The hubby and I wanted to do brunch on...</td>\n",
       "      <td>2010-06-21</td>\n",
       "      <td>A2aCzGCgg6gAbatHiCrPfA</td>\n",
       "      <td>rhM01fl3iU0xHr3TIpCMhQ</td>\n",
       "      <td>m5_GCJP2W4zEJnyVgxa3eA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yep, I've giving Yolk 5 stars. It's just reall...</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>DK2pd</td>\n",
       "      <td>SNHKDgmGiLn5chUlhdLCkg</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meat, meat, meat. It's meat-tastic. So much me...</td>\n",
       "      <td>2006-03-10</td>\n",
       "      <td>b3BkUiWJEKNQko</td>\n",
       "      <td>HXjk1RVfLMPeZxitnk1Auw</td>\n",
       "      <td>43rd1LKcZRIunySzbMsyLQ</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I caught up with the law school girls on a Sat...</td>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>RabHhte</td>\n",
       "      <td>W0ny0BqO0OJ4K4aVnSIlBw</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28063</th>\n",
       "      <td>This afternoon I went to Yolk with my college ...</td>\n",
       "      <td>2008-05-08</td>\n",
       "      <td>AoNuz5VBHjul-xWpp7Nbbg</td>\n",
       "      <td>JU96tV1CNyw5G03Yv79PRA</td>\n",
       "      <td>CwPi6NVuJIZZx4IBcTekFQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28064</th>\n",
       "      <td>Place has lots of side dishes. But that's abou...</td>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>F4b9FwPxyMRQO86eFiyYEA</td>\n",
       "      <td>IpVFQuWk4gEgQQ_XmzjeQQ</td>\n",
       "      <td>_n3OmwreEGPQmiHKklsD8w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28065</th>\n",
       "      <td>I am a huge fan of Brazillian steakhouses I've...</td>\n",
       "      <td>2010-03-11</td>\n",
       "      <td>D6Vel2u0lHi7QJK-jx</td>\n",
       "      <td>-vywj5I_Bh1FOzTe_sbQUw</td>\n",
       "      <td>43rd1LKcZRIunySzbMsyLQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>Great Brunch.\\n</td>\n",
       "      <td>2011-03-09</td>\n",
       "      <td>JSZrJ1yvndgXSKazIBkAOg</td>\n",
       "      <td>sjR61dvvQODav54vBNk0cg</td>\n",
       "      <td>dKcO9OQ44RPRlkWe-vToFA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28067</th>\n",
       "      <td>I love The Chicago Diner. I first came here ab...</td>\n",
       "      <td>2010-10-10</td>\n",
       "      <td>zTSZdljMJlXWL-vC72dzkg</td>\n",
       "      <td>sI9qKo-i2fGPxNBfJEY-kw</td>\n",
       "      <td>o54U2VkQama8FI30qDkWvw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28068 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review       date  \\\n",
       "0      dear longman & eagle.......you've left me no c... 2012-03-15   \n",
       "1      Delish. The hubby and I wanted to do brunch on... 2010-06-21   \n",
       "2      yep, I've giving Yolk 5 stars. It's just reall... 2011-07-29   \n",
       "3      Meat, meat, meat. It's meat-tastic. So much me... 2006-03-10   \n",
       "4      I caught up with the law school girls on a Sat... 2012-08-28   \n",
       "...                                                  ...        ...   \n",
       "28063  This afternoon I went to Yolk with my college ... 2008-05-08   \n",
       "28064  Place has lots of side dishes. But that's abou... 2012-08-12   \n",
       "28065  I am a huge fan of Brazillian steakhouses I've... 2010-03-11   \n",
       "28066                                    Great Brunch.\\n 2011-03-09   \n",
       "28067  I love The Chicago Diner. I first came here ab... 2010-10-10   \n",
       "\n",
       "                    review_id             reviewer_id             business_id  \\\n",
       "0      -s77HISu8DVQ8F0HxmWW6A  mthr7h15a_z9m9jRI6mG6Q  m5_GCJP2W4zEJnyVgxa3eA   \n",
       "1      A2aCzGCgg6gAbatHiCrPfA  rhM01fl3iU0xHr3TIpCMhQ  m5_GCJP2W4zEJnyVgxa3eA   \n",
       "2                       DK2pd  SNHKDgmGiLn5chUlhdLCkg  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "3              b3BkUiWJEKNQko  HXjk1RVfLMPeZxitnk1Auw  43rd1LKcZRIunySzbMsyLQ   \n",
       "4                     RabHhte  W0ny0BqO0OJ4K4aVnSIlBw  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "...                       ...                     ...                     ...   \n",
       "28063  AoNuz5VBHjul-xWpp7Nbbg  JU96tV1CNyw5G03Yv79PRA  CwPi6NVuJIZZx4IBcTekFQ   \n",
       "28064  F4b9FwPxyMRQO86eFiyYEA  IpVFQuWk4gEgQQ_XmzjeQQ  _n3OmwreEGPQmiHKklsD8w   \n",
       "28065      D6Vel2u0lHi7QJK-jx  -vywj5I_Bh1FOzTe_sbQUw  43rd1LKcZRIunySzbMsyLQ   \n",
       "28066  JSZrJ1yvndgXSKazIBkAOg  sjR61dvvQODav54vBNk0cg  dKcO9OQ44RPRlkWe-vToFA   \n",
       "28067  zTSZdljMJlXWL-vC72dzkg  sI9qKo-i2fGPxNBfJEY-kw  o54U2VkQama8FI30qDkWvw   \n",
       "\n",
       "       vote_funny  vote_cool  vote_useful  rating  total_votes  \\\n",
       "0               0          1            3       1            4   \n",
       "1               0          0            0       5            0   \n",
       "2               1          0            1       5            2   \n",
       "3              17          3            3       3           23   \n",
       "4               0          0            0       3            0   \n",
       "...           ...        ...          ...     ...          ...   \n",
       "28063           0          0            0       1            0   \n",
       "28064           0          0            0       1            0   \n",
       "28065           0          0            5       5            5   \n",
       "28066           0          0            0       5            0   \n",
       "28067           0          0            0       5            0   \n",
       "\n",
       "       percentage_vote_funny  percentage_vote_cool  percentage_vote_useful  \\\n",
       "0                    0.00000              0.250000                0.750000   \n",
       "1                    0.00000              0.000000                0.000000   \n",
       "2                    0.50000              0.000000                0.500000   \n",
       "3                    0.73913              0.130435                0.130435   \n",
       "4                    0.00000              0.000000                0.000000   \n",
       "...                      ...                   ...                     ...   \n",
       "28063                0.00000              0.000000                0.000000   \n",
       "28064                0.00000              0.000000                0.000000   \n",
       "28065                0.00000              0.000000                1.000000   \n",
       "28066                0.00000              0.000000                0.000000   \n",
       "28067                0.00000              0.000000                0.000000   \n",
       "\n",
       "       year  \n",
       "0      2012  \n",
       "1      2010  \n",
       "2      2011  \n",
       "3      2006  \n",
       "4      2012  \n",
       "...     ...  \n",
       "28063  2008  \n",
       "28064  2012  \n",
       "28065  2010  \n",
       "28066  2011  \n",
       "28067  2010  \n",
       "\n",
       "[28068 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling/Oversampling doesn't seem to work... Reducing number of training instances is hurting accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, SVM is O(n^3). Therefore, it is use feature selection... Going to use filter method 'SelectKBest'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBest = SelectKBest(chi2, k = 500)\n",
    "KBest.fit(X_train, y_train)\n",
    "X_train_best = KBest.transform(X_train)\n",
    "X_test_best = KBest.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm grid search too expensive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'linear', C = 1)\n",
    "svc.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = svc.score(X_test_best, y_test)\n",
    "print(\"multinominal naive bayes accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(svc, X_test_best, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_best = KBest.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with feature selection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_KBest = RandomForestClassifier()\n",
    "cross_val_score(rfc, X_best, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without feature selection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "cross_val_score(rfc, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_KBest = RandomForestClassifier()\n",
    "rfc_KBest.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rfc_KBest.score(X_test_best, y_test)\n",
    "print(\"random forest classifier accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(rfc_KBest, X_test_best, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "cross_val_score(ada, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ada.predict(X_test)\n",
    "score = ada.score(X_test, y_test)\n",
    "print(\"multinominal naive bayes accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(ada, X_test, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train_best, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doest do any better with feature selection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = ada.score(X_test_best, y_test)\n",
    "print(\"multinominal naive bayes accuracy: {:.4f}\".format(score))\n",
    "plot_confusion_matrix(ada, X_test_best, y_test, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression seems to be the best individual classifier. Lets trying tinkering around with some Logistic Regression parameters before we trying stacking the learners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train the mnb classifier using all the data and these hyperparameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngrams in range(1, 4):\n",
    "    \n",
    "    X = train_data.review\n",
    "    y = train_data.rating\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words = 'english', ngram_range = (1, ngrams))\n",
    "    vectorizer.fit(X)\n",
    "    X = vectorizer.transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "    \n",
    "    logreg = LogisticRegression(C = 0.1, max_iter = 1000000, penalty = 'l2')\n",
    "    logreg.fit(X_train, y_train)\n",
    "    score = logreg.score(X_test, y_test)\n",
    "    \n",
    "    print(\"ngrams = {}, logistic regression score is {}\".format(ngrams, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with feature selection using ngrams = 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.review\n",
    "y = train_data.rating\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "\n",
    "KBest = SelectKBest(chi2, k = 500)\n",
    "KBest.fit(X_train, y_train)\n",
    "X_train_best = KBest.transform(X_train)\n",
    "X_test_best = KBest.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression(C = 0.1, max_iter = 1000000, penalty = 'l2')\n",
    "logreg.fit(X_train_best, y_train)\n",
    "score = logreg.score(X_test_best, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.review\n",
    "y = train_data.rating\n",
    "\n",
    "other_features = ['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']\n",
    "features = train_data[other_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "# stack the other features\n",
    "from scipy import sparse\n",
    "X = sparse.hstack((X, np.array(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C = 0.1, max_iter = 1000000, penalty = 'l2')\n",
    "logreg.fit(X_train, y_train)\n",
    "score = logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "X = train_data[['review', 'total_votes', 'vote_funny', 'vote_cool', 'vote_useful']]\n",
    "y = train_data['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "\n",
    "X_train_clfs, X_train_meta, y_train_clfs, y_train_meta = train_test_split(X_train, y_train, train_size = 0.8, random_state = 0)\n",
    "\n",
    "classifiers = {\n",
    "    \"mnb\": MultinomialNB(alpha = 1),\n",
    "    \"rfc\": RandomForestClassifier(),\n",
    "    \"lr\": LogisticRegression(max_iter=1000000, C = 0.1, penalty = 'l2'),\n",
    "    \"svm\":  SVC(kernel = 'linear', C = 1.0),\n",
    "    \"adaboost\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "clfs = []\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "vectorizer.fit(X_train_clfs.review)\n",
    "\n",
    "X_train_clfs_review = vectorizer.transform(X_train_clfs.review)\n",
    "other_features = ['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']\n",
    "X_train_clfs = sparse.hstack((X_train_clfs_review, np.array(X_train_clfs[other_features])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mnb\n",
      "training rfc\n",
      "training lr\n",
      "training svm\n",
      "training adaboost\n"
     ]
    }
   ],
   "source": [
    "for classifier in list(classifiers.keys()):\n",
    "    \n",
    "    print(\"training {}\".format(classifier))\n",
    "    \n",
    "    clf = classifiers[classifier]\n",
    "    \n",
    "    clf.fit(X_train_clfs, y_train_clfs)\n",
    "    \n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = {}\n",
    "\n",
    "for clf in clfs:\n",
    "    \n",
    "        X_test_review = vectorizer.transform(X_test.review)\n",
    "        other_features = ['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']\n",
    "        X_test_sparse = sparse.hstack((X_test_review, np.array(X_test[other_features])))\n",
    "        predictions = clf.predict(X_test_sparse)\n",
    "        predictions_dict[clf.__class__] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{sklearn.naive_bayes.MultinomialNB: array([5, 5, 5, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.ensemble._forest.RandomForestClassifier: array([5, 5, 5, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.linear_model._logistic.LogisticRegression: array([5, 5, 3, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.svm._classes.SVC: array([5, 5, 3, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.ensemble._weight_boosting.AdaBoostClassifier: array([5, 5, 5, ..., 5, 5, 5], dtype=int64)}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(predictions_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = list(combinations(keys, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'sklearn.naive_bayes.MultinomialNB'>, <class 'sklearn.ensemble._forest.RandomForestClassifier'>, <class 'sklearn.linear_model._logistic.LogisticRegression'>):\n",
      "    0.7604203776273601\n",
      "(<class 'sklearn.naive_bayes.MultinomialNB'>, <class 'sklearn.ensemble._forest.RandomForestClassifier'>, <class 'sklearn.svm._classes.SVC'>):\n",
      "    0.7589953687210546\n",
      "(<class 'sklearn.naive_bayes.MultinomialNB'>, <class 'sklearn.ensemble._forest.RandomForestClassifier'>, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>):\n",
      "    0.7470609191307446\n",
      "(<class 'sklearn.naive_bayes.MultinomialNB'>, <class 'sklearn.linear_model._logistic.LogisticRegression'>, <class 'sklearn.svm._classes.SVC'>):\n",
      "    0.8664054150338439\n",
      "(<class 'sklearn.naive_bayes.MultinomialNB'>, <class 'sklearn.linear_model._logistic.LogisticRegression'>, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>):\n",
      "    0.8302458140363377\n",
      "(<class 'sklearn.naive_bayes.MultinomialNB'>, <class 'sklearn.svm._classes.SVC'>, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>):\n",
      "    0.8282864267901674\n",
      "(<class 'sklearn.ensemble._forest.RandomForestClassifier'>, <class 'sklearn.linear_model._logistic.LogisticRegression'>, <class 'sklearn.svm._classes.SVC'>):\n",
      "    0.8640897755610972\n",
      "(<class 'sklearn.ensemble._forest.RandomForestClassifier'>, <class 'sklearn.linear_model._logistic.LogisticRegression'>, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>):\n",
      "    0.817598859992875\n",
      "(<class 'sklearn.ensemble._forest.RandomForestClassifier'>, <class 'sklearn.svm._classes.SVC'>, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>):\n",
      "    0.8158175988599928\n",
      "(<class 'sklearn.linear_model._logistic.LogisticRegression'>, <class 'sklearn.svm._classes.SVC'>, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>):\n",
      "    0.8697898111863199\n"
     ]
    }
   ],
   "source": [
    "combos = list(combinations(keys, 3))\n",
    "for combo in combos:\n",
    "    pred1 = predictions_dict[combo[0]]\n",
    "    pred2 = predictions_dict[combo[1]]\n",
    "    pred3 = predictions_dict[combo[2]]\n",
    "    predictions_df = pd.DataFrame(np.stack((pred1, pred2, pred3)).transpose())\n",
    "    predictions_df = predictions_df.rename(columns = {0: \"pred1\", 1: \"pred2\", 2: \"pred3\"})\n",
    "    predictions_df['mode'] = predictions_df.apply(lambda x: Counter([x[\"pred1\"], x[\"pred2\"], x[\"pred3\"]]).most_common(1)[0][0], axis = 1)\n",
    "    score = accuracy_score(predictions_df['mode'], y_test)\n",
    "    print('''{}:\n",
    "    {}'''.format(combo, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8574991093694335"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(list(predictions_dict.values())[3], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = predictions_dict[combo[0]]\n",
    "pred2 = predictions_dict[combo[1]]\n",
    "pred3 = predictions_dict[combo[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8697898111863199"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(np.stack((pred1, pred2, pred3)).transpose())\n",
    "predictions_df = predictions_df.rename(columns = {0: \"pred1\", 1: \"pred2\", 2: \"pred3\"})\n",
    "predictions_df['mode'] = predictions_df.apply(lambda x: Counter([x[\"pred1\"], x[\"pred2\"], x[\"pred3\"]]).most_common(1)[0][0], axis = 1)\n",
    "accuracy_score(predictions_df['mode'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"mnb\": MultinomialNB(alpha = 1),\n",
    "    \"rfc\": RandomForestClassifier(),\n",
    "    \"lr\": LogisticRegression(max_iter=1000000, C = 0.1, penalty = 'l2'),\n",
    "    \"svm\":  SVC(kernel = 'linear', C = 1.0),\n",
    "    \"adaboost\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 5, ..., 2, 2, 3],\n",
       "       [5, 5, 5, ..., 0, 0, 0],\n",
       "       [5, 5, 3, ..., 3, 2, 3],\n",
       "       ...,\n",
       "       [5, 5, 5, ..., 0, 0, 1],\n",
       "       [5, 5, 5, ..., 0, 0, 0],\n",
       "       [5, 5, 5, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4491, 9)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb\n",
      "classifier mnb score is 0.6626291414321339\n",
      "rfc\n",
      "classifier rfc score is 0.8656929105806911\n",
      "lr\n",
      "classifier lr score is 0.871571072319202\n",
      "svm\n",
      "classifier svm score is 0.8726398289989312\n",
      "adaboost\n",
      "classifier adaboost score is 0.8729960812255076\n"
     ]
    }
   ],
   "source": [
    "for meta_classifier in list(classifiers.keys()):\n",
    "    \n",
    "    print(meta_classifier)\n",
    "    \n",
    "    meta_clf = classifiers[meta_classifier]\n",
    "    meta_clf.fit(X_train_meta, y_train_meta)\n",
    "    \n",
    "    X_test_review = vectorizer.transform(X_test.review)\n",
    "    \n",
    "    predictions_list = []\n",
    "    \n",
    "    for clf in clfs:\n",
    "\n",
    "        predictions = clf.predict(X_test_review)\n",
    "        predictions_list.append(predictions)\n",
    "        \n",
    "    clf_predictions = np.stack(predictions_list).transpose()\n",
    "    X_test_meta = np.column_stack((clf_predictions, np.array(X_test[['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']])))\n",
    "        \n",
    "    meta_score = meta_clf.score(X_test_meta, np.array(y_test))\n",
    "    \n",
    "    print(\"classifier {} score is {}\".format(meta_classifier, meta_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta_classifier in list(classifiers.keys()):\n",
    "    \n",
    "    print(meta_classifier)\n",
    "    \n",
    "    meta_clf = classifiers[meta_classifier]\n",
    "    meta_clf.fit(X_train_meta, y_train_meta)\n",
    "    \n",
    "    X_test_review = vectorizer.transform(X_test.review)\n",
    "    \n",
    "    predictions_list = []\n",
    "    \n",
    "    for clf in clfs:\n",
    "\n",
    "        predictions = clf.predict(X_test_review)\n",
    "        predictions_list.append(predictions)\n",
    "        \n",
    "    clf_predictions = np.stack(predictions_list).transpose()\n",
    "    X_test_meta = np.column_stack((clf_predictions, np.array(X_test[['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']])))\n",
    "        \n",
    "    meta_score = meta_clf.score(X_test_meta, np.array(y_test))\n",
    "    \n",
    "    print(\"classifier {} score is {}\".format(meta_classifier, meta_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._weight_boosting.AdaBoostClassifier"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = {}\n",
    "    \n",
    "for clf in clfs:\n",
    "\n",
    "    predictions = clf.predict(X_test_review)\n",
    "    predictions_list[clf.__class__] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{sklearn.naive_bayes.MultinomialNB: array([5, 5, 5, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.ensemble._forest.RandomForestClassifier: array([5, 5, 5, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.linear_model._logistic.LogisticRegression: array([5, 5, 3, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.svm._classes.SVC: array([5, 5, 3, ..., 5, 5, 5], dtype=int64),\n",
       " sklearn.ensemble._weight_boosting.AdaBoostClassifier: array([5, 5, 5, ..., 5, 5, 5], dtype=int64)}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_meta, y_train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9067022934758405"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train_meta, y_train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = []\n",
    "\n",
    "X_test_review = vectorizer.transform(X_test.review)\n",
    "\n",
    "for clf in clfs:\n",
    "    \n",
    "        predictions = clf.predict(X_test_review)\n",
    "        predictions_list.append(predictions)\n",
    "        \n",
    "predictions = np.stack(predictions_list).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.column_stack((predictions, np.array(X_test[['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8662272889205558"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_meta = sparse.hstack((X_train_meta_review, np.array(X_train_meta[['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(train_data[['rating', 'review']], random_state = 0)\n",
    "folds = np.array_split(train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[['review', 'total_votes', 'vote_funny', 'vote_cool', 'vote_useful']]\n",
    "y = train_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON COUNTVECTORIZER\n",
      "\n",
      "            RFC took 36.19 seconds to train\n",
      "            and has training accuracy 0.987 and testing accuracy 0.786\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            RFC took 36.41 seconds to train\n",
      "            and has training accuracy 0.987 and testing accuracy 0.784\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            RFC took 36.90 seconds to train\n",
      "            and has training accuracy 0.987 and testing accuracy 0.786\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            RFC took 36.54 seconds to train\n",
      "            and has training accuracy 0.987 and testing accuracy 0.781\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            RFC took 37.18 seconds to train\n",
      "            and has training accuracy 0.987 and testing accuracy 0.780\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "the mean test score for RFC was 0.783\n",
      "\n",
      "            XGB took 32.18 seconds to train\n",
      "            and has training accuracy 0.953 and testing accuracy 0.856\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            XGB took 33.60 seconds to train\n",
      "            and has training accuracy 0.952 and testing accuracy 0.853\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            XGB took 31.48 seconds to train\n",
      "            and has training accuracy 0.950 and testing accuracy 0.845\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            XGB took 33.44 seconds to train\n",
      "            and has training accuracy 0.952 and testing accuracy 0.849\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            XGB took 29.98 seconds to train\n",
      "            and has training accuracy 0.952 and testing accuracy 0.844\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "the mean test score for XGB was 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            LR took 4.41 seconds to train\n",
      "            and has training accuracy 0.950 and testing accuracy 0.862\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            LR took 4.43 seconds to train\n",
      "            and has training accuracy 0.948 and testing accuracy 0.858\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            LR took 4.01 seconds to train\n",
      "            and has training accuracy 0.950 and testing accuracy 0.857\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            LR took 4.46 seconds to train\n",
      "            and has training accuracy 0.950 and testing accuracy 0.855\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alecy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            LR took 4.94 seconds to train\n",
      "            and has training accuracy 0.954 and testing accuracy 0.859\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "the mean test score for LR was 0.858\n",
      "\n",
      "            SVMLINEAR took 618.65 seconds to train\n",
      "            and has training accuracy 0.995 and testing accuracy 0.842\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n",
      "\n",
      "            SVMLINEAR took 600.04 seconds to train\n",
      "            and has training accuracy 0.994 and testing accuracy 0.839\n",
      "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "X = train_data[['review', 'total_votes', 'vote_funny', 'vote_cool', 'vote_useful']]\n",
    "y = train_data['rating']\n",
    "\n",
    "\n",
    "\n",
    "meta_X\n",
    "\n",
    "for classifier in list(classifiers.keys()):\n",
    "    \n",
    "    clf = classifiers[classifier]\n",
    "    \n",
    "    test_scores = []\n",
    "    \n",
    "    for fold_n in range(5):\n",
    "        \n",
    "        \n",
    "        train_folds = [folds[i] for i in range(len(folds)) if i != fold_n]\n",
    "        train_fold = pd.concat(train_folds, axis = 0)\n",
    "        \n",
    "        test_fold = folds[fold_n]\n",
    "\n",
    "        X_train_txt, y_train = train_fold[\"review\"], np.array(train_fold[\"rating\"])\n",
    "        X_test_txt, y_test = test_fold[\"review\"], np.array(test_fold[\"rating\"])\n",
    "        \n",
    "        vectorser = CountVectorizer(ngram_range=(1, 1))\n",
    "        vectoriser.fit(X_train_txt)\n",
    "        X_train = vectoriser.transform(X_train_txt)\n",
    "        X_test = vectoriser.transform(X_test_txt)\n",
    "        \n",
    "        # If its the RFC, optimise it by feature selecting\n",
    "        if(classifier == \"RFC\"):\n",
    "            x2 = SelectKBest(chi2, k=1000)\n",
    "            X_train = x2.fit_transform(X_train, y_train)\n",
    "            X_test = x2.transform(X_test)\n",
    "\n",
    "        before = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        after = time.time()\n",
    "        train_time = after - before\n",
    "\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        test_score = clf.score(X_test, y_test)\n",
    "        \n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        print(\n",
    "            '''\n",
    "            {} took {:.2f} seconds to train\n",
    "            and has training accuracy {:.3f} and testing accuracy {:.3f}\n",
    "            - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "            '''.format(classifier, train_time, train_score, test_score)\n",
    "        )\n",
    "    \n",
    "    mean_test_score = np.mean(test_scores)\n",
    "    \n",
    "    print(\"the mean test score for {} was {:.3f}\".format(classifier, mean_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "seems like the doc2vec vectors aren't as informative as the countVectoriser  \n",
    "best to use ngrams(1,1) for doc2vecs? (1,2) causes marginal difference in other models, but causes around a 10% accuracy dip for multinomial  \n",
    "RFC gains around 7-8% accuracy if trained using chi2 features  \n",
    "of course, chi2 can't be used for d2v inputs as they contain negative values  \n",
    "MNB also can't be used for d2v inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All except MNB:  \n",
    "first do for d2v_50_train  84~  \n",
    "stacking ~ 85% for 50  \n",
    "86.2% for 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "RFC accuracy 0.7278232988956181\n",
      "ADA accuracy 0.7502671891699323\n",
      "XGB accuracy 0.8120769504809405\n",
      "LR accuracy 0.8350552190951194\n",
      "SVMLINEAR accuracy 0.8339864624153901\n",
      "TIME:  706.2092406749725\n",
      "stacking accuracy is 0.8626193529998575\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-9f7f072d91ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mclfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} accuracy {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectoriser = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "scores = []\n",
    "\n",
    "classifiers = {\n",
    "    #\"MNB\": MultinomialNB(),\n",
    "    \"RFC\": RandomForestClassifier(max_depth = 50),\n",
    "    \"ADA\": AdaBoostClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"LR\": LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, C = 0.1),\n",
    "    \"SVMLINEAR\":  SVC(kernel='linear', C=1.0)\n",
    "}\n",
    "\n",
    "# Include the meta features with the doc2vec\n",
    "dataframe = pd.concat([d2v_200_train.reset_index(), train_meta.reset_index()], axis = 1)\n",
    "# Above concat method causes duplicating index column\n",
    "dataframe = dataframe.loc[:,~dataframe.columns.duplicated()]\n",
    "dataframe = dataframe.drop(columns = ['index'])\n",
    "    \n",
    "train = shuffle(dataframe, random_state = 0)\n",
    "folds = np.array_split(train, 5)\n",
    "\n",
    "\n",
    "# loop\n",
    "\n",
    "for fold_n in range(5):\n",
    "    \n",
    "    print(fold_n)\n",
    "    \n",
    "    train_folds = [folds[i] for i in range(len(folds)) if i != fold_n]\n",
    "    train_fold = pd.concat(train_folds, axis = 0)\n",
    "    test_fold = folds[fold_n]\n",
    "    \n",
    "    meta_train, meta_test = train_test_split(dataframe)\n",
    "    \n",
    "    # split and train the model. Include all columns other than rating in training\n",
    "    X_train, y_train = train_fold[train_fold.columns.difference([\"rating\"])], np.array(train_fold[\"rating\"])\n",
    "    X_test, y_test = test_fold[train_fold.columns.difference([\"rating\"])], np.array(test_fold[\"rating\"])\n",
    "\n",
    "    before = time.time()\n",
    "    clfs = []\n",
    "    predictions_list = []\n",
    "    \n",
    "    for classifier in list(classifiers.keys()):\n",
    "\n",
    "        clf = classifiers[classifier]\n",
    "        clfs.append(clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(\"{} accuracy {}\".format(classifier, score))\n",
    "        predictions = clf.predict(X_test)\n",
    "        predictions_list.append(predictions)\n",
    "\n",
    "    after = time.time()\n",
    "    print(\"TIME: \", after - before)\n",
    "    meta_clf = RandomForestClassifier()\n",
    "    meta_clf.fit(np.stack(predictions_list).transpose(), y_test)\n",
    "\n",
    "    # lets test the meta classifier on the meta test data\n",
    "\n",
    "    reviews = meta_test\n",
    "    new_predictions = []\n",
    "    \n",
    "    # Predict the test set without rating column\n",
    "    for clf in clfs:\n",
    "        predictions = clf.predict(meta_test[meta_test.columns.difference([\"rating\"])])\n",
    "        new_predictions.append(predictions)\n",
    "\n",
    "    score = meta_clf.score(np.stack(new_predictions).transpose(), meta_test.rating)\n",
    "    scores.append(score)\n",
    "    print(\"stacking accuracy is {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459455607809605"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now try for splitVectorised()\n",
    "same as mike, but small changes to parameters in model. also trains random forest classifier differently to others (feature selection)   \n",
    "Using meta_clf = Logit:  \n",
    "all except mnb give 86.5  \n",
    "all except svm give 86.7, with lemmatokenizer and stop words 85%   \n",
    "all except mnb and svm gives 86.6    \n",
    "all except rfc = 86.5  \n",
    "using metaclf = XBG:  \n",
    "all except svm sometimes 77 most times 87.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "MNB accuracy 0.7537402042270245\n",
      "RFC accuracy 0.7964853953930183\n",
      "ADA accuracy 0.7891237235810972\n",
      "XGB accuracy 0.8537164568985989\n",
      "LR accuracy 0.8727143196390406\n",
      "SVMLINEAR accuracy 0.865590121111375\n",
      "TIME 788.207319021225\n",
      "stacking accuracy is 0.8540686903235001\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-2d91e5bf0203>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mX_test_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_fold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"review\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_fold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mvectoriser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectoriser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectoriser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \"\"\"\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1165\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1218\u001b[0m                                                        max_features)\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[1;34m(self, X, vocabulary)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \"\"\"\n\u001b[0;32m   1042\u001b[0m         \u001b[0msorted_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[0mmap_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectoriser = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "scores = []\n",
    "\n",
    "classifiers = {\n",
    "    \"MNB\": MultinomialNB(),\n",
    "    \"RFC\": RandomForestClassifier(max_depth = 50),\n",
    "    \"ADA\": AdaBoostClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"LR\": LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, C = 0.1),\n",
    "    \"SVMLINEAR\":  SVC(kernel='linear', C=0.1)\n",
    "}\n",
    "\n",
    "# loop\n",
    "\n",
    "train = shuffle(train_data[['rating', 'review']], random_state = 0)\n",
    "folds = np.array_split(train, 5)\n",
    "\n",
    "for fold_n in range(5):\n",
    "    \n",
    "    print(fold_n)\n",
    "    \n",
    "    meta_train, meta_test = train_test_split(train_data[['rating', 'review']])\n",
    "    train = shuffle(meta_train)\n",
    "    \n",
    "    folds = np.array_split(train, 5)\n",
    "\n",
    "    train_folds = [folds[i] for i in range(len(folds)) if i != fold_n]\n",
    "    train_fold = pd.concat(train_folds, axis = 0)\n",
    "    test_fold = folds[fold_n]\n",
    "\n",
    "    X_train_txt, y_train = train_fold[\"review\"], np.array(train_fold[\"rating\"])\n",
    "    X_test_txt, y_test = test_fold[\"review\"], np.array(test_fold[\"rating\"])\n",
    "\n",
    "    vectoriser.fit(X_train_txt)\n",
    "    X_train = vectoriser.transform(X_train_txt)\n",
    "    X_test = vectoriser.transform(X_test_txt)\n",
    "\n",
    "    before = time.time()\n",
    "    \n",
    "    clfs = []\n",
    "    \n",
    "    predictions_list = []\n",
    "    \n",
    "    for classifier in list(classifiers.keys()):\n",
    "\n",
    "        clf = classifiers[classifier]\n",
    "        clfs.append(clf)\n",
    "        \n",
    "        # could so some feature selection here potentially, or train separate models differently\n",
    "        if(\"RFC\" in classifiers and classifier == \"RFC\"):\n",
    "            # Optimise RFC with feature selection. Train the model using these k features\n",
    "            x2 = SelectKBest(chi2, k=1000)\n",
    "            X_train_rfc = x2.fit_transform(X_train, y_train)\n",
    "            X_test_rfc = x2.transform(X_test)\n",
    "            \n",
    "            clf.fit(X_train_rfc, y_train)\n",
    "            \n",
    "            score = clf.score(X_test_rfc, y_test)\n",
    "            print(\"{} accuracy {}\".format(classifier, score))\n",
    "            \n",
    "            predictions = clf.predict(X_test_rfc)\n",
    "            \n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            print(\"{} accuracy {}\".format(classifier, score))\n",
    "            predictions = clf.predict(X_test)\n",
    "            \n",
    "        predictions_list.append(predictions)\n",
    "\n",
    "    after = time.time()\n",
    "    print(\"TIME\", after - before)\n",
    "    \n",
    "    #meta_clf = RandomForestClassifier()\n",
    "    #meta_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    #meta_clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, C = 0.1)\n",
    "    #meta_clf = SVC(kernel='linear', C=1.0)\n",
    "    meta_clf = XGBClassifier()\n",
    "    \n",
    "    meta_clf.fit(np.stack(predictions_list).transpose(), y_test)\n",
    "\n",
    "    # lets test the meta classifier on the meta test data\n",
    "\n",
    "    reviews = vectoriser.transform(meta_test.review)\n",
    "    new_predictions = []\n",
    "    \n",
    "    for clf in clfs:\n",
    "        if(\"RFC\" in classifiers and clf == classifiers[\"RFC\"]):\n",
    "            # Select best k features in meta_test\n",
    "            x2 = SelectKBest(chi2, k=1000)\n",
    "            reviews_rfc = x2.fit_transform(reviews, meta_test.rating)\n",
    "            predictions = clf.predict(reviews_rfc)\n",
    "        else:\n",
    "            predictions = clf.predict(reviews)\n",
    "            \n",
    "        new_predictions.append(predictions)\n",
    "\n",
    "    score = meta_clf.score(np.stack(new_predictions).transpose(), meta_test.rating)\n",
    "    scores.append(score)\n",
    "    print(\"stacking accuracy is {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try some kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrained with vectorised features\u001b[0m\n",
      "The accuracy of the predictions is: 0.87068\n",
      "\n",
      "Confusion Matrix of Correctly Labeled Classes %'s\n",
      "\n",
      "Predicted         1         3         5\n",
      "Truths                                 \n",
      "1          0.669528  0.053613  0.003885\n",
      "3          0.193133  0.692308  0.041699\n",
      "5          0.137339  0.254079  0.954416\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Just normal Logistic regression model\n",
    "# using count vectoriser\n",
    "print('\\033[1m' + f\"Trained with vectorised features\" '\\033[0m')\n",
    "X_train, X_vali, Y_train, Y_vali, vectoriser = splitVectorised((1,2))\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000).fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_vali)\n",
    "evaluate(Y_pred, Y_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, ..., 3, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectoriser.transform(test_text.review)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>6989</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>6990</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>6991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>6992</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>6993</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>6994</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>6995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>6996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>6997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>6998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>6999</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>7000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>7001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>7002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>7003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>7004</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>7005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>7006</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>7007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>7008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7008</th>\n",
       "      <td>7009</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>7010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>7011</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>7012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>7013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>7014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>7015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>7016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>7017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>7018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7018 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instance_id  rating\n",
       "0               1       5\n",
       "1               2       5\n",
       "2               3       1\n",
       "3               4       3\n",
       "4               5       5\n",
       "5               6       5\n",
       "6               7       5\n",
       "7               8       5\n",
       "8               9       5\n",
       "9              10       5\n",
       "10             11       5\n",
       "11             12       5\n",
       "12             13       5\n",
       "13             14       5\n",
       "14             15       5\n",
       "15             16       1\n",
       "16             17       5\n",
       "17             18       5\n",
       "18             19       5\n",
       "19             20       5\n",
       "20             21       5\n",
       "21             22       1\n",
       "22             23       5\n",
       "23             24       3\n",
       "24             25       3\n",
       "25             26       5\n",
       "26             27       5\n",
       "27             28       3\n",
       "28             29       5\n",
       "29             30       3\n",
       "...           ...     ...\n",
       "6988         6989       5\n",
       "6989         6990       5\n",
       "6990         6991       5\n",
       "6991         6992       3\n",
       "6992         6993       3\n",
       "6993         6994       3\n",
       "6994         6995       5\n",
       "6995         6996       5\n",
       "6996         6997       5\n",
       "6997         6998       5\n",
       "6998         6999       5\n",
       "6999         7000       3\n",
       "7000         7001       5\n",
       "7001         7002       5\n",
       "7002         7003       5\n",
       "7003         7004       5\n",
       "7004         7005       5\n",
       "7005         7006       5\n",
       "7006         7007       5\n",
       "7007         7008       5\n",
       "7008         7009       5\n",
       "7009         7010       5\n",
       "7010         7011       5\n",
       "7011         7012       1\n",
       "7012         7013       3\n",
       "7013         7014       5\n",
       "7014         7015       5\n",
       "7015         7016       3\n",
       "7016         7017       5\n",
       "7017         7018       5\n",
       "\n",
       "[7018 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsdf = pd.DataFrame(list(enumerate(Y_pred, start = 1)))\n",
    "predictionsdf = predictionsdf.rename(columns = {0: 'instance_id', 1: 'rating'})\n",
    "predictionsdf.to_csv(\"preds1.csv\", index = False)\n",
    "predictionsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy 0.8818583440216616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the stacking model now\n",
    "\n",
    "vectoriser = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "scores = []\n",
    "\n",
    "classifiers = {\n",
    "    #\"MNB\": MultinomialNB(),\n",
    "    #\"RFC\": RandomForestClassifier(max_depth = 50),\n",
    "    #\"ADA\": AdaBoostClassifier(),\n",
    "    #\"XGB\": XGBClassifier(),\n",
    "    \"LR\": LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, C = 0.1)\n",
    "    #\"SVMLINEAR\":  SVC(kernel='linear', C=1.0)\n",
    "}\n",
    "\n",
    "# loop\n",
    "\n",
    "\n",
    "meta_train, meta_test = train_test_split(train_data[['rating', 'review']])\n",
    "train = shuffle(meta_train)\n",
    "    \n",
    "vectoriser.fit(X_train_txt)\n",
    "X_train = vectoriser.transform(meta_train.review)\n",
    "Y_train = meta_train.rating\n",
    "\n",
    "X_test = vectoriser.transform(meta_test.review)\n",
    "y_test = meta_test.rating\n",
    "    \n",
    "clfs = []\n",
    "\n",
    "predictions_list = []\n",
    "    \n",
    "for classifier in list(classifiers.keys()):\n",
    "\n",
    "    clf = classifiers[classifier]\n",
    "    clfs.append(clf)\n",
    "        \n",
    "    # could so some feature selection here potentially, or train separate models differently\n",
    "    if(\"RFC\" in classifiers and classifier == \"RFC\"):\n",
    "        # Optimise RFC with feature selection. Train the model using these k features\n",
    "        x2 = SelectKBest(chi2, k=1000)\n",
    "        X_train_rfc = x2.fit_transform(X_train, y_train)\n",
    "        X_test_rfc = x2.transform(X_test)\n",
    "            \n",
    "        clf.fit(X_train_rfc, Y_train)\n",
    "            \n",
    "        score = clf.score(X_test_rfc, y_test)\n",
    "        print(\"{} accuracy {}\".format(classifier, score))\n",
    "            \n",
    "        predictions = clf.predict(X_test_rfc)\n",
    "            \n",
    "    else:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(\"{} accuracy {}\".format(classifier, score))\n",
    "        predictions = clf.predict(X_test)\n",
    "            \n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "#meta_clf = RandomForestClassifier()\n",
    "#meta_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "meta_clf = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000, C = 0.1)\n",
    "#meta_cld = SVC(kernel='linear', C=1.0)\n",
    "    \n",
    "meta_clf.fit(np.stack(predictions_list).transpose(), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, ..., 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectoriser.transform(test_text.review)\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "for classifier in list(classifiers.keys()):\n",
    "\n",
    "    clf = classifiers[classifier]\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    predictions_list.append(predictions)\n",
    "    \n",
    "predictions = meta_clf.predict(np.stack(predictions_list).transpose())\n",
    "\n",
    "predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.review\n",
    "y = train_data.rating\n",
    "\n",
    "other_features = ['total_votes', 'vote_funny', 'vote_cool', 'vote_useful']\n",
    "features = train_data[other_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "vectorizer.fit(X)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "# stack the other features\n",
    "from scipy import sparse\n",
    "X = sparse.hstack((X, np.array(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBest = SelectKBest(chi2, k = 1000)\n",
    "KBest.fit(X, y)\n",
    "X_train_best = KBest.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 0.1, max_iter = 1000000, penalty = 'l2')\n",
    "logreg.fit(X_train_best, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = test_data.review\n",
    "X_predict = vectorizer.transform(X_predict)\n",
    "\n",
    "test_data['total_votes'] = test_data['vote_funny'] + test_data['vote_cool'] + test_data['vote_useful']\n",
    "features = test_data[other_features]\n",
    "X_predict = sparse.hstack((X_predict, np.array(features)))\n",
    "\n",
    "X_predict = KBest.transform(X_predict)\n",
    "\n",
    "predictions = logreg.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, ..., 3, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>7014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>7015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>7016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>7017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>7018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7018 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instance_id  rating\n",
       "0               1       5\n",
       "1               2       5\n",
       "2               3       1\n",
       "3               4       3\n",
       "4               5       5\n",
       "...           ...     ...\n",
       "7013         7014       5\n",
       "7014         7015       5\n",
       "7015         7016       3\n",
       "7016         7017       5\n",
       "7017         7018       5\n",
       "\n",
       "[7018 rows x 2 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsdf = pd.DataFrame(list(enumerate(predictions, start = 1)))\n",
    "predictionsdf = predictionsdf.rename(columns = {0: 'instance_id', 1: 'rating'})\n",
    "predictionsdf.to_csv(\"logistic_regression.csv\", index = False)\n",
    "predictionsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
